{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXJHno0qY49dT8F4KaltAI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/223t1a3105/colab-saved-data/blob/main/Deep_Learning_Lab_1(27_07_24).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MDVohLxcGnG",
        "outputId": "a9bab4f8-8685-448c-caa1-2f05a6a16fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar value: 5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Scalar example\n",
        "scalar = np.array(5)\n",
        "print(\"Scalar value:\", scalar)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector example\n",
        "vector = np.array([1, 2, 3])\n",
        "print(\"Vector values:\", vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYuRyMdVdzV_",
        "outputId": "c93ed582-de6a-4d2b-d5fa-11f3ed2fb328"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector values: [1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB 1"
      ],
      "metadata": {
        "id": "BBQkHx5Lea4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Scalar example\n",
        "scalar = np.array(5)\n",
        "print(\"Scalar value:\", scalar)\n",
        "\n",
        "# Vector example\n",
        "vector = np.array([1, 2, 3])\n",
        "print(\"Vector values:\", vector)\n",
        "\n",
        "# 2D Tensor (Matrix) example\n",
        "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"2D Tensor (Matrix):\\n\", matrix)\n",
        "\n",
        "# 3D Tensor example\n",
        "tensor_3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
        "print(\"3D Tensor:\\n\", tensor_3d)\n",
        "\n",
        "# 4D Tensor example\n",
        "tensor_4d = np.random.rand(2, 3, 4, 5)\n",
        "print(\"Shape of 4D Tensor:\", tensor_4d.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_50Nd4We-Se",
        "outputId": "43f8bb34-2feb-418a-8ec3-f63f10e1515e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar value: 5\n",
            "Vector values: [1 2 3]\n",
            "2D Tensor (Matrix):\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "3D Tensor:\n",
            " [[[ 1  2  3]\n",
            "  [ 4  5  6]]\n",
            "\n",
            " [[ 7  8  9]\n",
            "  [10 11 12]]]\n",
            "Shape of 4D Tensor: (2, 3, 4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROGRAM TO PREDICT SUM OF TWO NUMBERS"
      ],
      "metadata": {
        "id": "cR7ctjOlfPtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GshUQ1g2gI6s",
        "outputId": "5e915021-7faa-4e8c-fe49-05a30affe967"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 1s 3ms/step - loss: 9712.7842 - val_loss: 7086.8286\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3754.8523 - val_loss: 496.2448\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 108.1862 - val_loss: 24.2409\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 17.9462 - val_loss: 11.9151\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 8.7920 - val_loss: 5.7781\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 6.0846\n",
            "Test Loss: 6.08463191986084\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "Predicted Sum: 66.96077728271484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=64, batch_size=35, validation_split=0.3)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji9WR2BZiBY2",
        "outputId": "26d5b912-96d1-4027-c745-48e5609deb0f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 2579.8394 - val_loss: 260.6056\n",
            "Epoch 2/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 44.4196 - val_loss: 10.0937\n",
            "Epoch 3/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 6.0894 - val_loss: 3.7780\n",
            "Epoch 4/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0897 - val_loss: 2.6125\n",
            "Epoch 5/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 2.3617 - val_loss: 2.1228\n",
            "Epoch 6/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.9196 - val_loss: 1.7229\n",
            "Epoch 7/64\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.5563 - val_loss: 1.3997\n",
            "Epoch 8/64\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.2584 - val_loss: 1.1378\n",
            "Epoch 9/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0218 - val_loss: 0.9270\n",
            "Epoch 10/64\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.8361 - val_loss: 0.7641\n",
            "Epoch 11/64\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.6966 - val_loss: 0.6402\n",
            "Epoch 12/64\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5856 - val_loss: 0.5371\n",
            "Epoch 13/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 0.4554\n",
            "Epoch 14/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.4237 - val_loss: 0.3858\n",
            "Epoch 15/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.3217\n",
            "Epoch 16/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2964 - val_loss: 0.2698\n",
            "Epoch 17/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2421 - val_loss: 0.2167\n",
            "Epoch 18/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1947 - val_loss: 0.1743\n",
            "Epoch 19/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1564 - val_loss: 0.1377\n",
            "Epoch 20/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1236 - val_loss: 0.1105\n",
            "Epoch 21/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.0877\n",
            "Epoch 22/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0688\n",
            "Epoch 23/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0547\n",
            "Epoch 24/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0435\n",
            "Epoch 25/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0350\n",
            "Epoch 26/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0282\n",
            "Epoch 27/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0229\n",
            "Epoch 28/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0185\n",
            "Epoch 29/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0151\n",
            "Epoch 30/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0127\n",
            "Epoch 31/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0103\n",
            "Epoch 32/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0084\n",
            "Epoch 33/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0069\n",
            "Epoch 34/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0055\n",
            "Epoch 35/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0044\n",
            "Epoch 36/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0034\n",
            "Epoch 37/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 38/64\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 39/64\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 40/64\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 41/64\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 8.9262e-04 - val_loss: 7.1849e-04\n",
            "Epoch 42/64\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 6.0957e-04 - val_loss: 4.9207e-04\n",
            "Epoch 43/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 4.0816e-04 - val_loss: 3.2458e-04\n",
            "Epoch 44/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6467e-04 - val_loss: 2.0528e-04\n",
            "Epoch 45/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.6951e-04 - val_loss: 1.2658e-04\n",
            "Epoch 46/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0126e-04 - val_loss: 7.5573e-05\n",
            "Epoch 47/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 5.9796e-05 - val_loss: 4.3824e-05\n",
            "Epoch 48/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.5472e-05 - val_loss: 2.5983e-05\n",
            "Epoch 49/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1064e-05 - val_loss: 1.5774e-05\n",
            "Epoch 50/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3284e-05 - val_loss: 1.0491e-05\n",
            "Epoch 51/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.0520e-06 - val_loss: 8.2784e-06\n",
            "Epoch 52/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 7.0068e-06 - val_loss: 6.1873e-06\n",
            "Epoch 53/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 5.9198e-06 - val_loss: 5.6376e-06\n",
            "Epoch 54/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6407e-06 - val_loss: 5.2663e-06\n",
            "Epoch 55/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 5.3523e-06 - val_loss: 5.7478e-06\n",
            "Epoch 56/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 5.5452e-06 - val_loss: 5.0013e-06\n",
            "Epoch 57/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 4.9955e-06 - val_loss: 5.0058e-06\n",
            "Epoch 58/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.9665e-06 - val_loss: 4.9934e-06\n",
            "Epoch 59/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0054e-06 - val_loss: 4.5349e-06\n",
            "Epoch 60/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 4.6007e-06 - val_loss: 7.0265e-06\n",
            "Epoch 61/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5716e-06 - val_loss: 4.3809e-06\n",
            "Epoch 62/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5389e-06 - val_loss: 4.1618e-06\n",
            "Epoch 63/64\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.4596e-06 - val_loss: 8.3516e-06\n",
            "Epoch 64/64\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 4.1830e-06 - val_loss: 3.6938e-06\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 3.7805e-06\n",
            "Test Loss: 3.7804584280820563e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d46266a5a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "Predicted Sum: 67.99661254882812\n"
          ]
        }
      ]
    }
  ]
}